{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkVjRvScRBCT",
        "outputId": "6a48e456-10d7-41df-9c7e-4e5ccb52b0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TbTYjL6RcYc",
        "outputId": "fa61e0d8-4177-4acf-beef-5f2d0fcd64b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-models\n",
            "  Downloading keras_models-0.0.7-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from keras-models) (1.0.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-models) (2.8.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-models) (7.1.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from keras-models) (2.2.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-models) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-models) (1.21.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (4.63.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (0.9.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->keras-models) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->keras-models) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->keras-models) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->keras-models) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras-models) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras-models) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras-models) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras-models) (1.24.3)\n",
            "Installing collected packages: keras-models\n",
            "Successfully installed keras-models-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBtV95N4Rel1",
        "outputId": "78ac72a4-4016-45d6-87e5-993f04c20676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting noisereduce\n",
            "  Downloading noisereduce-2.0.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from noisereduce) (4.63.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from noisereduce) (0.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from noisereduce) (3.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->noisereduce) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->noisereduce) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->noisereduce) (3.0.7)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->noisereduce) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa->noisereduce) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->noisereduce) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->noisereduce) (3.10.0.2)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import noisereduce as nr\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from noisereduce.noisereduce import reduce_noise"
      ],
      "metadata": {
        "id": "5T7IsniTRhWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/AudioDataset/Maindataset/MyAudio\"\n",
        "JSON_PATH = \"/content/drive/MyDrive/Model/data1.json\"\n",
        "SAMPLE_RATE = 44080\n",
        "TRACK_DURATION = 3  # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=1):\n",
        "    \n",
        "\n",
        "   \n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"labels\": [],\n",
        "        \"mfcc\": [],\n",
        "        \"files\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "   \n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        \n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            \n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            \n",
        "            for f in filenames:\n",
        "\n",
        "\t\t            \n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                \n",
        "                for d in range(num_segments):\n",
        "\n",
        "                    \n",
        "                    start = samples_per_segment * d\n",
        "                    finish = start + samples_per_segment\n",
        "\n",
        "                    signal = nr.reduce_noise(y=signal[start:finish], sr=sample_rate)\n",
        "\n",
        "\n",
        "                    \n",
        "                    mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                    mfcc = mfcc.T\n",
        "\n",
        "                    \n",
        "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        data[\"files\"].append(file_path)\n",
        "#                         print(\"{}, segment:{}\".format(file_path, d+1))\n",
        "\n",
        "    # save MFCCs to json file\n",
        "    with open(json_path, \"w\",encoding=\"utf-8\") as fp:\n",
        "        json.dump(data, fp,ensure_ascii=False, indent=4)\n",
        "        \n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D6e0T3VRvGW",
        "outputId": "cc7b2de8-348a-4d8e-8c19-c0e7c4dfc77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: এক নাম্বার বাতি নিভাও\n",
            "\n",
            "Processing: এক নাম্বার বাতি জ্বালানো হোক\n",
            "\n",
            "Processing: দুই নাম্বার বাতি নিভাও\n",
            "\n",
            "Processing: এক নাম্বার পাখা বন্ধ করো\n",
            "\n",
            "Processing: এক নাম্বার পাখা চালাও\n",
            "\n",
            "Processing: দরজা খোলো\n",
            "\n",
            "Processing: দুই নাম্বার পাখা চালাও\n",
            "\n",
            "Processing: দরজা বন্ধ করো\n",
            "\n",
            "Processing: দুই নাম্বার বাতি জ্বালাও\n",
            "\n",
            "Processing: দুই নাম্বার পাখা বন্ধ করো\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Model/data1.json\"\n",
        "SAVED_MODEL_PATH = \"model5.h5\"\n",
        "EPOCHS = 48\n",
        "BATCH_SIZE = 40\n",
        "PATIENCE = 5\n",
        "LEARNING_RATE = 0.0001"
      ],
      "metadata": {
        "id": "Y_o6UOEwRy-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "with open(DATA_PATH, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"labels\"])\n",
        "\n",
        "print(\"Training sets loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVxbAtQbSQfj",
        "outputId": "8e8c9abf-323b-4541-a6a8-41e0a7b09d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.2\n",
        "validation_size = 0.2\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "X_validation = X_validation[..., np.newaxis]"
      ],
      "metadata": {
        "id": "DWMQ8FzESTfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "print(input_shape)\n",
        "\n",
        "# build network architecture using convolutional layers\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# 1st conv layer\n",
        "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape,\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "# 2nd conv layer\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "# 3rd conv layer\n",
        "model.add(tf.keras.layers.Conv2D(64, (2, 2), activation='relu',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
        "\n",
        "# flatten output and feed into dense layer1\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "# softmax output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "optimiser = tf.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# print model parameters on console\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHRdmZ38Sbv3",
        "outputId": "d761dbb8-3b29-4dc2-8e5a-b47fea81231b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259, 13, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 257, 11, 16)       160       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 257, 11, 16)      64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 129, 6, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 127, 4, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 127, 4, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 2, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 63, 1, 64)         8256      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 63, 1, 64)        256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 1, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 145,290\n",
            "Trainable params: 145,066\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=PATIENCE)\n",
        "     \n",
        "#train model\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=(X_validation, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMRtY7CpSdcf",
        "outputId": "c0ac1769-9941-4588-d2f5-0a3dd1af0db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/48\n",
            "46/46 [==============================] - 9s 163ms/step - loss: 2.3311 - accuracy: 0.2461 - val_loss: 2.4432 - val_accuracy: 0.1788\n",
            "Epoch 2/48\n",
            "46/46 [==============================] - 6s 137ms/step - loss: 1.4961 - accuracy: 0.5448 - val_loss: 2.0256 - val_accuracy: 0.2781\n",
            "Epoch 3/48\n",
            "46/46 [==============================] - 6s 136ms/step - loss: 1.0345 - accuracy: 0.7257 - val_loss: 1.6812 - val_accuracy: 0.4172\n",
            "Epoch 4/48\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 0.7266 - accuracy: 0.8424 - val_loss: 1.3400 - val_accuracy: 0.5519\n",
            "Epoch 5/48\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.5250 - accuracy: 0.8971 - val_loss: 1.0303 - val_accuracy: 0.6755\n",
            "Epoch 6/48\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.3966 - accuracy: 0.9452 - val_loss: 0.7719 - val_accuracy: 0.8146\n",
            "Epoch 7/48\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.3187 - accuracy: 0.9602 - val_loss: 0.5989 - val_accuracy: 0.8786\n",
            "Epoch 8/48\n",
            "46/46 [==============================] - 7s 159ms/step - loss: 0.2570 - accuracy: 0.9751 - val_loss: 0.4455 - val_accuracy: 0.9227\n",
            "Epoch 9/48\n",
            "46/46 [==============================] - 7s 162ms/step - loss: 0.2153 - accuracy: 0.9845 - val_loss: 0.3631 - val_accuracy: 0.9404\n",
            "Epoch 10/48\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 0.1849 - accuracy: 0.9906 - val_loss: 0.3113 - val_accuracy: 0.9492\n",
            "Epoch 11/48\n",
            "46/46 [==============================] - 7s 147ms/step - loss: 0.1657 - accuracy: 0.9939 - val_loss: 0.2748 - val_accuracy: 0.9558\n",
            "Epoch 12/48\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.1459 - accuracy: 0.9983 - val_loss: 0.2503 - val_accuracy: 0.9558\n",
            "Epoch 13/48\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 0.1340 - accuracy: 0.9983 - val_loss: 0.2308 - val_accuracy: 0.9581\n",
            "Epoch 14/48\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9581\n",
            "Epoch 15/48\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.1134 - accuracy: 0.9994 - val_loss: 0.2043 - val_accuracy: 0.9603\n",
            "Epoch 16/48\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9647\n",
            "Epoch 17/48\n",
            "46/46 [==============================] - 7s 146ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9625\n",
            "Epoch 18/48\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9647\n",
            "Epoch 19/48\n",
            "46/46 [==============================] - 7s 147ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9691\n",
            "Epoch 20/48\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9669\n",
            "Epoch 21/48\n",
            "46/46 [==============================] - 7s 146ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9691\n",
            "Epoch 22/48\n",
            "46/46 [==============================] - 7s 146ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9735\n",
            "Epoch 23/48\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9691\n",
            "Epoch 24/48\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9735\n",
            "Epoch 25/48\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.0797 - accuracy: 0.9994 - val_loss: 0.1549 - val_accuracy: 0.9713\n",
            "Epoch 26/48\n",
            "46/46 [==============================] - 7s 145ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9735\n",
            "Epoch 27/48\n",
            "46/46 [==============================] - 7s 146ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9779\n",
            "Epoch 28/48\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9779\n",
            "Epoch 29/48\n",
            "46/46 [==============================] - 7s 147ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9779\n",
            "Epoch 30/48\n",
            "46/46 [==============================] - 7s 151ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9779\n",
            "Epoch 31/48\n",
            "46/46 [==============================] - 7s 147ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9823\n",
            "Epoch 32/48\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9823\n",
            "Epoch 33/48\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9823\n",
            "Epoch 34/48\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9845\n",
            "Epoch 35/48\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9801\n",
            "Epoch 36/48\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9823\n",
            "Epoch 37/48\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9801\n",
            "Epoch 38/48\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9823\n",
            "Epoch 39/48\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9801\n",
            "Epoch 40/48\n",
            "46/46 [==============================] - 7s 145ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9801\n",
            "Epoch 41/48\n",
            "46/46 [==============================] - 7s 149ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9823\n",
            "Epoch 42/48\n",
            "46/46 [==============================] - 7s 150ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9823\n",
            "Epoch 43/48\n",
            "46/46 [==============================] - 7s 150ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9823\n",
            "Epoch 44/48\n",
            "46/46 [==============================] - 7s 148ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9823\n",
            "Epoch 45/48\n",
            "46/46 [==============================] - 7s 150ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9823\n",
            "Epoch 46/48\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9801\n",
            "Epoch 47/48\n",
            "46/46 [==============================] - 7s 145ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9845\n",
            "Epoch 48/48\n",
            "46/46 [==============================] - 7s 145ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2)\n",
        "\n",
        "# create accuracy subplot\n",
        "axs[0].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "axs[0].plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "axs[0].set_ylabel(\"Accuracy\")\n",
        "axs[0].legend(loc=\"lower right\")\n",
        "axs[0].set_title(\"Accuracy evaluation\")\n",
        "\n",
        "# create loss subplot\n",
        "axs[1].plot(history.history[\"loss\"], label=\"loss\")\n",
        "axs[1].plot(history.history['val_loss'], label=\"val_loss\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "axs[1].set_ylabel(\"Loss\")\n",
        "axs[1].legend(loc=\"upper right\")\n",
        "axs[1].set_title(\"Loss evaluation\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Nq62vvqESlbr",
        "outputId": "bbdacf1c-af0a-4782-9883-160365d758f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgA4nuOxSolG",
        "outputId": "6d507649-7901-403c-c128-df4b5d6e4e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1361 - accuracy: 0.9806\n",
            "\n",
            "Test loss: 0.13612811267375946, test accuracy: 98.05653691291809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(SAVED_MODEL_PATH)"
      ],
      "metadata": {
        "id": "xzN1NBV6SpqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.load_model(\"model5.h5\")"
      ],
      "metadata": {
        "id": "H-PQ0fkSSs03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRECISION, RECALL, F1-SCORE\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "def maxIndex(arr) :\n",
        "    mx = 0\n",
        "    mxIndx = -1\n",
        "    for indx, val in enumerate(arr):\n",
        "        if val > mx:\n",
        "            mx = val\n",
        "            mxIndx = indx\n",
        "    return mxIndx\n",
        " \n",
        "total_commands = 10\n",
        "pos_reg = np.zeros(total_commands)\n",
        "fal_reg = np.zeros(total_commands)\n",
        "total = np.zeros(total_commands)\n",
        " \n",
        "for indx, res in enumerate(pred):\n",
        "    target = int(y_test[indx])\n",
        "    \n",
        "    total[target] += 1\n",
        "    pred_class = maxIndex(res)\n",
        "    \n",
        "    if target == pred_class :\n",
        "        pos_reg[target] += 1\n",
        "    else:\n",
        "        fal_reg[pred_class] += 1\n",
        " \n",
        "# print(total, '\\n', pos_reg,'\\n',fal_reg)\n",
        "\n",
        "s1=0\n",
        "s2=0\n",
        "s3=0\n",
        "for i in range(total_commands):\n",
        "    s1+=pos_reg[i]\n",
        "    s2+=total[i]\n",
        "    s3+=fal_reg[i]\n",
        " \n",
        "# print(s1,\"  \",s2,\"  \",s3);\n",
        "print(\"precesion: \",s1/(s1+s3),\" recall: \",s1/s2, \"f1 score :\",(2*(s1/(s1+s3)))*(s1/s2)/((s1/(s1+s3))+(s1/s2)))\n",
        "print()\n",
        " \n",
        "for i in range(total_commands):\n",
        "    print(i, \": \", (pos_reg[i] / total[i] * 100),\"  precision : \",pos_reg[i]/(pos_reg[i]+fal_reg[i]),\" recall : \",pos_reg[i]/total[i],\" f1score: \", (2*(pos_reg[i]/(pos_reg[i]+fal_reg[i]))*(pos_reg[i]/total[i]))/((pos_reg[i]/(pos_reg[i]+fal_reg[i]))+(pos_reg[i]/total[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_OlKPmNS2-e",
        "outputId": "ce282ca9-3e61-4594-d40f-722f94189499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precesion:  0.980565371024735  recall:  0.980565371024735 f1 score : 0.980565371024735\n",
            "\n",
            "0 :  97.05882352941177   precision :  0.9428571428571428  recall :  0.9705882352941176  f1score:  0.9565217391304348\n",
            "1 :  98.30508474576271   precision :  0.9830508474576272  recall :  0.9830508474576272  f1score:  0.9830508474576272\n",
            "2 :  91.42857142857143   precision :  0.9696969696969697  recall :  0.9142857142857143  f1score:  0.9411764705882354\n",
            "3 :  98.46153846153847   precision :  1.0  recall :  0.9846153846153847  f1score:  0.9922480620155039\n",
            "4 :  100.0   precision :  0.9811320754716981  recall :  1.0  f1score:  0.9904761904761905\n",
            "5 :  98.21428571428571   precision :  0.9821428571428571  recall :  0.9821428571428571  f1score:  0.9821428571428571\n",
            "6 :  100.0   precision :  1.0  recall :  1.0  f1score:  1.0\n",
            "7 :  96.49122807017544   precision :  0.9649122807017544  recall :  0.9649122807017544  f1score:  0.9649122807017544\n",
            "8 :  100.0   precision :  0.9850746268656716  recall :  1.0  f1score:  0.9924812030075187\n",
            "9 :  98.21428571428571   precision :  1.0  recall :  0.9821428571428571  f1score:  0.9909909909909909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVED_MODEL_PATH = \"model5.h5\"\n",
        "SAMPLE_RATE = 44080\n",
        "TRACK_DURATION = 3 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "   \n",
        "\n",
        "    model = None\n",
        "    _mapping = [\n",
        "        \"এক নাম্বার বাতি নিভাও\",\n",
        "        \"এক নাম্বার বাতি জ্বালানো হোক\",\n",
        "        \"দুই নাম্বার বাতি নিভাও\",\n",
        "        \"এক নাম্বার পাখা বন্ধ করো\",\n",
        "        \"এক নাম্বার পাখা চালাও\",\n",
        "        \"দরজা খোলো\",\n",
        "        \"দুই নাম্বার পাখা চালাও\",\n",
        "        \"দরজা বন্ধ করো\",\n",
        "        \"দুই নাম্বার বাতি জ্বালাও\",\n",
        "        \"দুই নাম্বার পাখা বন্ধ করো\"\n",
        "    ]\n",
        "    _instance = None\n",
        "\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \n",
        "\n",
        "        \n",
        "        MFCCs = self.preprocess(file_path)\n",
        "\n",
        "        \n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        \n",
        "        predictions = self.model.predict(MFCCs)\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        return predicted_keyword\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=13, n_fft=2048, hop_length=512,num_segments=1):\n",
        "       \n",
        "        samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "        num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "        for d in range(num_segments):\n",
        "\n",
        "                    \n",
        "                    start = samples_per_segment * d\n",
        "                    finish = start + samples_per_segment\n",
        "\n",
        "                    signal = nr.reduce_noise(y=signal[start:finish], sr=sample_rate)\n",
        "\n",
        "                    \n",
        "                    MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                    mfcc = MFCCs.T\n",
        "\n",
        "                    \n",
        "        return mfcc\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \n",
        "\n",
        "    \n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "\n",
        "    # make a prediction\n",
        "    \n",
        "    \n",
        "    \n",
        "    keyword17 = kss.predict(\"/content/drive/MyDrive/AudioDataset/Maindataset/Test/duibatijalao(105).wav\")\n",
        "    keyword18 = kss.predict(\"/content/drive/MyDrive/AudioDataset/Maindataset/Test/duibatinibao(12).wav\")\n",
        "    keyword19 = kss.predict(\"/content/drive/MyDrive/AudioDataset/Maindataset/Test/duipakhaoff(26).wav\")\n",
        "    keyword20 = kss.predict(\"/content/drive/MyDrive/AudioDataset/Maindataset/Test/ekbatinibao(4).wav\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    print(keyword17)\n",
        "    print(keyword18)\n",
        "    print(keyword19)\n",
        "    print(keyword20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xul7s35sS-p4",
        "outputId": "d0d191f7-47af-484e-be56-c76bdb9dacb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "দুই নাম্বার বাতি জ্বালাও\n",
            "দুই নাম্বার বাতি নিভাও\n",
            "দুই নাম্বার পাখা বন্ধ করো\n",
            "এক নাম্বার বাতি নিভাও\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "\n",
        "model = load_model(\"model5.h5\")\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "print(\"model converted\")\n",
        "\n",
        "# Save the model.\n",
        "with open('model5.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJisEqokTDD2",
        "outputId": "d39faed7-de61-482f-e969-6501bffb7f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmphs_bjelh/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model converted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libsox-fmt-all libsox-dev sox > /dev/null\n",
        "! pip install torchaudio > /dev/null\n",
        "! python -m pip install git+https://github.com/facebookresearch/WavAugment.git > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdRmQG_1g-fR",
        "outputId": "718d2198-65f2-4169-e21c-90d4eb1619ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Running command git clone -q https://github.com/facebookresearch/WavAugment.git /tmp/pip-req-build-fjstti8f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python > /dev/null"
      ],
      "metadata": {
        "id": "aEez4nn1g-9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "# Download example from WavAugment\n",
        "! wget https://raw.githubusercontent.com/facebookresearch/WavAugment/master/tests/test.wav > /dev/null\n",
        "\n",
        "# and load it as a tensor\n",
        "x, sr = torchaudio.load('test.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4TEhqvXhAdn",
        "outputId": "f6de790f-791b-4011-a011-bf7177282da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 13:06:55--  https://raw.githubusercontent.com/facebookresearch/WavAugment/master/tests/test.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 454764 (444K) [audio/wav]\n",
            "Saving to: ‘test.wav’\n",
            "\n",
            "test.wav            100%[===================>] 444.11K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-28 13:06:56 (10.3 MB/s) - ‘test.wav’ saved [454764/454764]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code taken from https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "import tempfile\n",
        "import pathlib\n",
        "\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    path = pathlib.Path(tmpdirname) / 'tmp.wav'\n",
        "    with open(path, 'wb') as f:\n",
        "       f.write(riff)\n",
        "       \n",
        "    x, sr = torchaudio.load(path)\n",
        "\n",
        "  return x, sr"
      ],
      "metadata": {
        "id": "myHkT_fdhDpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, sr = get_audio()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "H6uSccAthiri",
        "outputId": "85e5ecb4-6f96-49fa-f777-dbc9ea5b1005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchaudio.save(\"/content/drive/MyDrive/Recordedfiles/Inputfiles/myfile.wav\", x, sr)\n",
        "save_mfcc(\"/content/drive/MyDrive/Recordedfiles\", \"/content/drive/MyDrive/Recordedfilesjson/myrecorded.json\", num_segments=1)\n",
        "with open(\"/content/drive/MyDrive/Recordedfilesjson/myrecorded.json\", \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "\n",
        "x = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"labels\"])\n",
        "\n",
        "x = x[..., np.newaxis]\n",
        "pred = model.predict(x)\n",
        "print(pred)\n",
        "mxval = maxIndex(pred[0])\n",
        "\n",
        "print(\"Predicted Class:: \", mxval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcO8i19vhlsc",
        "outputId": "a4f40732-6f01-4e46-b726-80ae357a165c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: Inputfiles\n",
            "\n",
            "Processing: .ipynb_checkpoints\n",
            "\n",
            "Processing: .ipynb_checkpoints\n",
            "[[3.3026421e-04 1.9630553e-04 1.0141503e-03 9.9531209e-01 3.3754369e-04\n",
            "  1.6496897e-04 1.0919236e-04 3.2665630e-06 1.2446554e-09 2.5321718e-03]]\n",
            "Predicted Class::  3\n"
          ]
        }
      ]
    }
  ]
}